title: Inside vs. out
date: 18-06-2016

One idea living close to the top of my mind is the [distinction](https://www.anderson.ucla.edu/faculty/keith.chen/negot.%20papers/KahnemanLovallo_ChoicForcastsRisk93.pdf) between inside and outside forecasting.

The other day, I was reminded of this when talking to a young entrepreneur. He was trying to make a big decision -- whether to shutter his startup or not -- and told me he was leaning towards carrying on. His odds of success were good enough to justify persevering, he said. I asked why he thought this; his reply was interesting. Basically, it was that [he knew himself](https://www.scientificamerican.com/podcast/episode/know-thyself-11-05-07/). He knew his plan. Knew his product. Knew his abilities, deficits. So there was risk in doubling down, yes. But it was calculated risk.

How calculated though?

What interested me about my friend's reply was what it lacked. [Missing](https://en.wikipedia.org/wiki/Base_rate_fallacy) was the [thing](file:///Users/JaspKH/Downloads/MoF52_Better_forecasting_for_large_capital_projects.pdf) [economists](https://pdfs.semanticscholar.org/1ded/6194f28ad2a50424e132417b6b42e8c7da65.pdf) see as most [relevant](https://en.wikipedia.org/wiki/Reference_class_forecasting) here: data about the world beyond self. Market conditions, regulatory backdrop, competitor's acts -- the outcome of my friend's startup depends as much on these as anything he does. Probably more, in fact. By assessing his odds using data in front of his nose only, my friend had neglected this. And as a result, he was very likely too [optimistic](https://en.wikipedia.org/wiki/Optimism_bias) about his startup's future.

My friend's mistake was to take the [inside view](https://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-insights/daniel-kahneman-beware-the-inside-view) -- one way we can predict stuff.

As [Michael Mauboussin](https://en.wikipedia.org/wiki/Michael_J._Mauboussin) discusses ([here](https://www.michaelmauboussin.com/excerpts/TTexcerpt.pdf)), the inside view is people's default way to forecast. Its essence: predicting stuff largely on the basis of perceptions about yourself. A few data points and positive illusions are the only inputs in such forecasts, usually. And so the forecasts themselves tend to be overoptimistic.

Lots of undue economic optimism for example is traceable to inside-view forecasts. The [ubiquity](https://en.wikipedia.org/wiki/Hofstadter%27s_law) of the [planning fallacy](https://web.mit.edu/curhan/www/docs/Articles/biases/67_J_Personality_and_Social_Psychology_366,_1994.pdf), [excess entry](https://www.jstor.org/stable/116990?seq=1#page_scan_tab_contents) and an [overactive](https://www.nber.org/papers/w22750) [M&A market](https://faculty.darden.virginia.edu/brunerb/Bruner_PDF/Does%20M&A%20Pay.pdf) are all partly caused by defaulting to that view.

This poses the question: can we correct for such forecasts? In theory, yeah. Just take the [outside view](https://wiki.lesswrong.com/wiki/Outside_view).

The outside view is a contrasting and less intuitive way to forecast. Rather than predict based on personal circumstance, this view tells you to consult other cases similar to yours and big enough to be statistically significant: [a reference class](https://en.wikipedia.org/wiki/Reference_class_forecasting). If you find the statistical features of this class -- the survival rate of certain startups, let's say -- and anchor your forecast to those stats, you'll better predict your own fate.

Take my entrepreneur friend. He forecasted on the basis of his perceived skills, plans, etc. But what if he'd taken the outside view? In this case, he would have mostly* discounted those perceptions. Instead, he would have asked: for people like me, growing a similar startup, what's the survival rate? If he anchored a forecast to that rate, it would almost definitely be more accurate than his actual forecast.

But also more sobering. [Which](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2094387) [is](https://news.nationalgeographic.com/news/2011/09/110914-optimism-narcissism-overconfidence-hubris-evolution-science-nature/) the [rub](https://stumblingandmumbling.typepad.com/stumbling_and_mumbling/2009/07/kevin-pietersen-rational-overconfidence.html) [here](https://escholarship.org/uc/item/5zz0q2r0#page-1).

Often, when you consult a reference class you see your odds are low -- so low, in fact, that the rational response is to fold. Yet few people do. Humans are irrational perseverers*. When faced with the choice, Daniel Kahneman noted, most of us would "rather give up our rationality than our enterprise".

For me, the inside-outside distinction therefore teaches an important lesson, one which perhaps explains its place in my mind. It's that human rationality has [sharp limits](https://en.wikiquote.org/wiki/Bounded_rationality). And that as an ideal rationality demands so (too?) much.

> **1.** *Mostly, but not wholly. Personal facts should inform the prediction, though only for fine-tuning purposes. > These facts are reasons to tweak your prediction either way from a base-rate (as described in depth [here](https://www.edge.org/conversation/philip_tetlock-a-short-course-in-superforecasting)).*

> **2.** *Is this necessarily a bad thing? Behaviour that is irrational for the individual can be desirable collectively. We all benefit from living in a society where people chase costly dreams despite a negligible chance of success. As Richard Nisbett [pointed out](https://www.hofstralawreview.org/wp-content/uploads/2014/05/54_9HofstraLRev16211980-1981.pdf):*

> *"We probably would have few novelists, actors or scientists if all potential aspirants to these careers took action based on a normatively justifiable probability of success. We might also have few new products, new medical procedures, new political movements or new scientific theories."*

> *The could have added that London or New York or Los Angeles would be barren in hours. Irrationality makes the world go 'round.*
